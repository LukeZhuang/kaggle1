{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import gzip\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "import math\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18793 21321\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "users=[]\n",
    "bussiness=[]\n",
    "ratings=[]\n",
    "for l in readGz(\"data/train.json.gz\"):\n",
    "    u=l['userID']\n",
    "    b=l['businessID']\n",
    "    r=float(l['rating'])\n",
    "    users.append(u)\n",
    "    bussiness.append(b)\n",
    "    ratings.append(r)\n",
    "    \n",
    "user_set=set(users)\n",
    "buss_set=set(bussiness)\n",
    "\n",
    "Nu=len(user_set)  # 18793\n",
    "Nb=len(buss_set)  # 21321\n",
    "\n",
    "user_index={}\n",
    "buss_index={}\n",
    "\n",
    "for (i,u) in enumerate(user_set):\n",
    "    user_index[u]=i\n",
    "for (i,b) in enumerate(buss_set):\n",
    "    buss_index[b]=i\n",
    "print(Nu,Nb)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "num_train=20000\n",
    "\n",
    "train_set=[]\n",
    "val_set=[]\n",
    "\n",
    "buss_u={}\n",
    "user_b={}\n",
    "\n",
    "n_train=0\n",
    "n_val=0\n",
    "\n",
    "total_rating_train=0\n",
    "\n",
    "for i in range(len(users)):\n",
    "    u=user_index[users[i]]\n",
    "    b=buss_index[bussiness[i]]\n",
    "    r=ratings[i]\n",
    "    if i<num_train:\n",
    "        total_rating_train+=r\n",
    "        train_set.append((u,b,r))\n",
    "        if u not in buss_u:\n",
    "            buss_u[u]=[(b,r)]\n",
    "        else:\n",
    "            buss_u[u].append((b,r))\n",
    "        if b not in user_b:\n",
    "            user_b[b]=[(u,r)]\n",
    "        else:\n",
    "            user_b[b].append((u,r))\n",
    "        n_train+=1\n",
    "    else:\n",
    "        val_set.append((u,b,r))\n",
    "        n_val+=1\n",
    "\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-06 14:58:33 iter 1, loss=68388.8835598471, RMSE=2.6151268336\n",
      "2017-11-06 14:58:34 iter 2, loss=31384.7516418933, RMSE=1.7715742051\n",
      "2017-11-06 14:58:34 iter 3, loss=16927.0601335359, RMSE=1.3010403581\n",
      "2017-11-06 14:58:35 iter 4, loss=9516.7610448864, RMSE=0.9755388790\n",
      "2017-11-06 14:58:35 iter 5, loss=5584.7503228839, RMSE=0.7473118708\n",
      "2017-11-06 14:58:36 iter 6, loss=3623.9697815898, RMSE=0.6019941679\n",
      "2017-11-06 14:58:36 iter 7, loss=2790.0593897114, RMSE=0.5282101277\n",
      "2017-11-06 14:58:37 iter 8, loss=2556.2195143293, RMSE=0.5055906956\n",
      "2017-11-06 14:58:38 iter 9, loss=2589.9280042440, RMSE=0.5089133526\n",
      "2017-11-06 14:58:38 iter 10, loss=2689.7080440837, RMSE=0.5186239528\n",
      "2017-11-06 14:58:39 iter 11, loss=2744.9620065343, RMSE=0.5239238501\n",
      "2017-11-06 14:58:39 iter 12, loss=2708.0080753060, RMSE=0.5203852491\n",
      "2017-11-06 14:58:40 iter 13, loss=2573.4361657419, RMSE=0.5072904657\n",
      "2017-11-06 14:58:40 iter 14, loss=2360.8631531099, RMSE=0.4858871426\n",
      "2017-11-06 14:58:41 iter 15, loss=2100.4356152085, RMSE=0.4583050965\n",
      "2017-11-06 14:58:41 iter 16, loss=1822.5930909923, RMSE=0.4269183869\n",
      "2017-11-06 14:58:42 iter 17, loss=1552.4076493177, RMSE=0.3940060468\n",
      "2017-11-06 14:58:42 iter 18, loss=1307.1683888628, RMSE=0.3615478376\n",
      "2017-11-06 14:58:43 iter 19, loss=1096.1498302221, RMSE=0.3310815353\n",
      "2017-11-06 14:58:43 iter 20, loss=921.8959450963, RMSE=0.3036273942\n",
      "2017-11-06 14:58:44 iter 21, loss=782.2338011323, RMSE=0.2796844295\n",
      "2017-11-06 14:58:44 iter 22, loss=672.3516871778, RMSE=0.2592974522\n",
      "2017-11-06 14:58:45 iter 23, loss=586.4919377210, RMSE=0.2421759562\n",
      "2017-11-06 14:58:45 iter 24, loss=519.0313185220, RMSE=0.2278225885\n",
      "2017-11-06 14:58:45 iter 25, loss=464.9740403036, RMSE=0.2156325672\n",
      "2017-11-06 14:58:46 iter 26, loss=420.1220170222, RMSE=0.2049687823\n",
      "2017-11-06 14:58:46 iter 27, loss=381.1622791730, RMSE=0.1952337776\n",
      "2017-11-06 14:58:47 iter 28, loss=345.7286089165, RMSE=0.1859377877\n",
      "2017-11-06 14:58:47 iter 29, loss=312.4210770925, RMSE=0.1767543711\n",
      "2017-11-06 14:58:48 iter 30, loss=280.7169707243, RMSE=0.1675461043\n",
      "2017-11-06 14:58:48 iter 31, loss=250.7210841787, RMSE=0.1583417457\n",
      "2017-11-06 14:58:49 iter 32, loss=222.8111024422, RMSE=0.1492685843\n",
      "2017-11-06 14:58:49 iter 33, loss=197.3265115920, RMSE=0.1404729553\n",
      "2017-11-06 14:58:50 iter 34, loss=174.4216591870, RMSE=0.1320687924\n",
      "2017-11-06 14:58:50 iter 35, loss=154.0685282975, RMSE=0.1241243442\n",
      "2017-11-06 14:58:51 iter 36, loss=136.1185507617, RMSE=0.1166698550\n",
      "2017-11-06 14:58:52 iter 37, loss=120.3562237557, RMSE=0.1097069842\n",
      "2017-11-06 14:58:52 iter 38, loss=106.5312346047, RMSE=0.1032139693\n",
      "2017-11-06 14:58:52 iter 39, loss=94.3848841274, RMSE=0.0971518832\n",
      "2017-11-06 14:58:53 iter 40, loss=83.6877965491, RMSE=0.0914810344\n",
      "2017-11-06 14:58:53 iter 41, loss=74.2784077584, RMSE=0.0861849220\n",
      "2017-11-06 14:58:54 iter 42, loss=66.0706020223, RMSE=0.0812838250\n",
      "2017-11-06 14:58:54 iter 43, loss=59.0186877552, RMSE=0.0768236212\n",
      "2017-11-06 14:58:55 iter 44, loss=53.0575945322, RMSE=0.0728406442\n",
      "2017-11-06 14:58:56 iter 45, loss=48.0519588876, RMSE=0.0693195203\n",
      "2017-11-06 14:58:56 iter 46, loss=43.7867161802, RMSE=0.0661715318\n",
      "2017-11-06 14:58:57 iter 47, loss=40.0110689289, RMSE=0.0632543034\n",
      "2017-11-06 14:58:57 iter 48, loss=36.5090377439, RMSE=0.0604227091\n",
      "2017-11-06 14:58:58 iter 49, loss=33.1513429752, RMSE=0.0575772029\n",
      "2017-11-06 14:58:58 iter 50, loss=29.9031521431, RMSE=0.0546837747\n",
      "2017-11-06 14:58:59 iter 51, loss=26.7924966043, RMSE=0.0517614689\n",
      "2017-11-06 14:58:59 iter 52, loss=23.8627386860, RMSE=0.0488495022\n",
      "2017-11-06 14:59:00 iter 53, loss=21.1373820842, RMSE=0.0459754087\n",
      "2017-11-06 14:59:00 iter 54, loss=18.6125802539, RMSE=0.0431422997\n",
      "2017-11-06 14:59:01 iter 55, loss=16.2712160123, RMSE=0.0403375954\n",
      "2017-11-06 14:59:01 iter 56, loss=14.1017625321, RMSE=0.0375523136\n",
      "2017-11-06 14:59:02 iter 57, loss=12.1100204034, RMSE=0.0347994546\n",
      "2017-11-06 14:59:02 iter 58, loss=10.3211452592, RMSE=0.0321265393\n",
      "2017-11-06 14:59:03 iter 59, loss=8.7737833339, RMSE=0.0296205728\n",
      "2017-11-06 14:59:03 iter 60, loss=7.5066318877, RMSE=0.0273982333\n",
      "2017-11-06 14:59:04 iter 61, loss=6.5391701646, RMSE=0.0255718012\n",
      "2017-11-06 14:59:04 iter 62, loss=5.8557826330, RMSE=0.0241987244\n",
      "2017-11-06 14:59:05 iter 63, loss=5.4033742141, RMSE=0.0232451591\n",
      "2017-11-06 14:59:05 iter 64, loss=5.1035474218, RMSE=0.0225910323\n",
      "2017-11-06 14:59:06 iter 65, loss=4.8730311338, RMSE=0.0220749431\n",
      "2017-11-06 14:59:07 iter 66, loss=4.6436763351, RMSE=0.0215491910\n",
      "2017-11-06 14:59:07 iter 67, loss=4.3739586665, RMSE=0.0209140113\n",
      "2017-11-06 14:59:08 iter 68, loss=4.0493162702, RMSE=0.0201229130\n",
      "2017-11-06 14:59:08 iter 69, loss=3.6755135763, RMSE=0.0191716290\n",
      "2017-11-06 14:59:09 iter 70, loss=3.2706279180, RMSE=0.0180848774\n",
      "2017-11-06 14:59:09 iter 71, loss=2.8579329606, RMSE=0.0169054221\n",
      "2017-11-06 14:59:09 iter 72, loss=2.4596196107, RMSE=0.0156831745\n",
      "2017-11-06 14:59:10 iter 73, loss=2.0924338918, RMSE=0.0144652476\n",
      "2017-11-06 14:59:10 iter 74, loss=1.7670205536, RMSE=0.0132929325\n",
      "2017-11-06 14:59:11 iter 75, loss=1.4897894803, RMSE=0.0122056933\n",
      "2017-11-06 14:59:11 iter 76, loss=1.2641106548, RMSE=0.0112432676\n",
      "2017-11-06 14:59:12 iter 77, loss=1.0899298661, RMSE=0.0104399706\n",
      "2017-11-06 14:59:12 iter 78, loss=0.9630589019, RMSE=0.0098135564\n",
      "2017-11-06 14:59:13 iter 79, loss=0.8750094158, RMSE=0.0093541938\n",
      "2017-11-06 14:59:13 iter 80, loss=0.8137481024, RMSE=0.0090207988\n",
      "2017-11-06 14:59:14 iter 81, loss=0.7657821767, RMSE=0.0087508981\n",
      "2017-11-06 14:59:14 iter 82, loss=0.7192782542, RMSE=0.0084810274\n",
      "2017-11-06 14:59:15 iter 83, loss=0.6667740408, RMSE=0.0081656233\n",
      "2017-11-06 14:59:15 iter 84, loss=0.6060697795, RMSE=0.0077850484\n",
      "2017-11-06 14:59:16 iter 85, loss=0.5392828324, RMSE=0.0073435879\n",
      "2017-11-06 14:59:16 iter 86, loss=0.4710325398, RMSE=0.0068631810\n",
      "2017-11-06 14:59:17 iter 87, loss=0.4065667755, RMSE=0.0063762589\n",
      "2017-11-06 14:59:17 iter 88, loss=0.3502520584, RMSE=0.0059182097\n",
      "2017-11-06 14:59:18 iter 89, loss=0.3045736523, RMSE=0.0055188192\n",
      "2017-11-06 14:59:18 iter 90, loss=0.2697473697, RMSE=0.0051937209\n",
      "2017-11-06 14:59:19 iter 91, loss=0.2440162388, RMSE=0.0049398000\n",
      "2017-11-06 14:59:19 iter 92, loss=0.2244487566, RMSE=0.0047376023\n",
      "2017-11-06 14:59:20 iter 93, loss=0.2079113985, RMSE=0.0045597302\n",
      "2017-11-06 14:59:20 iter 94, loss=0.1918563363, RMSE=0.0043801408\n",
      "2017-11-06 14:59:21 iter 95, loss=0.1747572844, RMSE=0.0041803981\n",
      "2017-11-06 14:59:21 iter 96, loss=0.1561484801, RMSE=0.0039515627\n",
      "2017-11-06 14:59:22 iter 97, loss=0.1364905516, RMSE=0.0036944628\n",
      "2017-11-06 14:59:22 iter 98, loss=0.1169127828, RMSE=0.0034192511\n",
      "2017-11-06 14:59:23 iter 99, loss=0.0988851032, RMSE=0.0031446002\n",
      "2017-11-06 14:59:23 iter 100, loss=0.0837177653, RMSE=0.0028934022\n"
     ]
    }
   ],
   "source": [
    "lamb=0.0\n",
    "max_iter=100\n",
    "print_every=1\n",
    "weight_scale=1\n",
    "\n",
    "alpha=total_rating_train/n_train\n",
    "beta_u=np.random.randn(Nu)*weight_scale\n",
    "beta_b=np.random.randn(Nb)*weight_scale\n",
    "\n",
    "K=30\n",
    "gamma_u=np.random.randn(Nu,K)*weight_scale\n",
    "gamma_b=np.random.randn(Nb,K)*weight_scale\n",
    "\n",
    "min_RMSE=None\n",
    "best_parameters=None\n",
    "\n",
    "def adam(x, dx, config=None):\n",
    "    if config is None: config = {}\n",
    "    config.setdefault('learning_rate', 3e-2)\n",
    "    config.setdefault('beta1', 0.9)\n",
    "    config.setdefault('beta2', 0.999)\n",
    "    config.setdefault('epsilon', 1e-8)\n",
    "    config.setdefault('m', np.zeros_like(x))\n",
    "    config.setdefault('v', np.zeros_like(x))\n",
    "    config.setdefault('t', 0)\n",
    "    next_x = None\n",
    "    config['t']+=1\n",
    "    config['m']=config['beta1']*config['m']+(1-config['beta1'])*dx\n",
    "    config['v']=config['beta2']*config['v']+(1-config['beta2'])*(dx**2)\n",
    "    m=config['m']/(1-config['beta1']**config['t'])\n",
    "    v=config['v']/(1-config['beta2']**config['t'])\n",
    "    next_x=x-config['learning_rate']*m/(np.sqrt(v)+config['epsilon'])\n",
    "    return next_x, config\n",
    "\n",
    "config_gamma_u=None\n",
    "config_gamma_b=None\n",
    "\n",
    "for it in range(max_iter):\n",
    "    \n",
    "    alpha=0\n",
    "    for (u,b,r) in train_set:\n",
    "        alpha+=(r-beta_u[u]-beta_b[b]-np.inner(gamma_u[u,:],gamma_b[b,:]))/n_train\n",
    "    for (u,b_r_list) in buss_u.items():\n",
    "        beta_u[u]=0\n",
    "        for (b,r) in b_r_list:\n",
    "            beta_u[u]+=(r-alpha-beta_b[b]-np.inner(gamma_u[u,:],gamma_b[b,:]))/(lamb+len(b_r_list))\n",
    "    for (b,u_r_list) in user_b.items():\n",
    "        beta_b[b]=0\n",
    "        for (u,r) in u_r_list:\n",
    "            beta_b[b]+=(r-alpha-beta_u[u]-np.inner(gamma_u[u,:],gamma_b[b,:]))/(lamb+len(u_r_list))\n",
    "    \n",
    "    dgamma_u=np.zeros((Nu,K))\n",
    "    dgamma_b=np.zeros((Nb,K))\n",
    "    \n",
    "    loss=0.0\n",
    "    RMSE=0.0\n",
    "    for (u,b,r) in train_set:\n",
    "        temp=(alpha+beta_u[u]+beta_b[b]+np.inner(gamma_u[u,:],gamma_b[b,:])-r)\n",
    "        loss+=0.5*temp**2\n",
    "        RMSE+=temp**2\n",
    "        dgamma_u[u,:]+=temp*gamma_b[b,:]\n",
    "        dgamma_b[b,:]+=temp*gamma_u[u,:]\n",
    "        \n",
    "    loss+=0.5*lamb*(np.sum(np.square(beta_u))+np.sum(np.square(beta_b))+np.sum(np.square(gamma_u))+np.sum(np.square(gamma_b)))\n",
    "    dgamma_u+=lamb*gamma_u\n",
    "    dgamma_b+=lamb*gamma_b\n",
    "\n",
    "    gamma_u,config_gamma_u=adam(gamma_u,dgamma_u,config_gamma_u)\n",
    "    gamma_b,config_gamma_b=adam(gamma_b,dgamma_b,config_gamma_b)\n",
    "    \n",
    "    RMSE/=n_train\n",
    "    RMSE=math.sqrt(RMSE)\n",
    "    \n",
    "    if it==0 or (it+1)%print_every==0:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),\n",
    "              'iter %d, loss=%.10f, RMSE=%.10f' %(it+1,loss,RMSE))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
